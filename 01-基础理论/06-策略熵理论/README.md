# 策略熵理论 (Policy Entropy Theory)

**Authors:** Damon Li

---

本章节深入探讨强化学习，特别是大型语言模型 (LLM) 应用中的**策略熵理论**。策略熵不仅是衡量模型探索能力的关键指标，其动态变化规律更是理解和突破现有 RL 训练瓶颈的核心。

我们将系统性地研究以下主题：

1.  **[信息熵与策略熵](./01-信息熵与策略熵/README.md)**: 从信息论的基础出发，建立策略熵的形式化定义，并探讨其在 RL 和 LLM 中的具体含义。

2.  **[熵变与协方差](./02-熵变与协方差/README.md)**: 深入推导策略熵在训练过程中的动态变化规律，揭示其与“动作对数概率”和“优势函数”之间协方差的内在数学关联，从而从理论上解释“熵崩溃”现象。

3.  **[熵与性能的经验定律](./03-熵与性能的经验定律/README.md)**: 分析策略熵与模型最终性能之间存在的、可被精确描述的指数关系。该经验定律不仅揭示了性能天花板的存在，还为性能预测提供了强大的数学工具。

4.  **[新型熵控制方法](./04-新型熵控制方法/README.md)**: 基于对熵变机制的深刻理解，详细介绍为解决“熵崩溃”而提出的新型熵控制方法，如 Clip-Cov 和 KL-Cov，并阐述其背后的数学原理。

通过对这些主题的深入研究，我们将为理解和解决大模型强化学习中的探索问题提供坚实的理论基础。
